# HWS operators
ai.onnx;9;Add,BatchNormalization,Cast,Concat,Constant,ConstantOfShape,Conv,Div,Equal,Exp,Expand,Floor,Gather,Gemm,Less,LogSoftmax,MatMul,Mul,Neg,NonZero,ReduceSum,Reshape,Shape,Sigmoid,Slice,Softmax,Softplus,Split,Squeeze,Sub,Tanh,Transpose,Unsqueeze,Where
ai.onnx;11;Concat,Constant,Gather,MatMul,Reshape,Shape,Transpose,Unsqueeze
ai.onnx;13;Add,BatchNormalization,Cast,Concat,Constant,ConstantOfShape,Conv,Equal,Expand,Gather,Mul,Pow,Range,ReduceSum,Reshape,ScatterND,Shape,Sigmoid,Slice,Transpose,Unsqueeze,Where

# internal ops added by optimizers
# Note: LayerNormalization is an internal op even though it is (incorrectly) registered in the ONNX domain.
ai.onnx;1;LayerNormalization
com.microsoft;1;DynamicQuantizeMatMul,FusedConv,FusedGemm,FusedMatMul,Gelu,MatMulIntegerToFloat,NhwcMaxPool,QLinearAdd,QLinearAveragePool,QLinearConv,QLinearGlobalAveragePool,QLinearMul,QLinearSigmoid,QuickGelu

# NHWC transformer also uses this, so assuming it's valuable enough to include
com.microsoft;1;QLinearLeakyRelu
